{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5efd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp hotspots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ece0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfc28a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from pathlib import Path\n",
    "import multiprocessing\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "from hdbscan import HDBSCAN\n",
    "\n",
    "from clip_plot.images import ImageFactory\n",
    "from clip_plot.utils import write_json, timestamp, get_json_path\n",
    "from clip_plot.configuration import ClusterSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2654cbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_cluster_model(min_cluster_size: int = 15):\n",
    "    \"\"\"Return model with .fit() method that can be used to cluster input vectors\n",
    "    \"\"\"\n",
    "    return HDBSCAN(\n",
    "        core_dist_n_jobs=multiprocessing.cpu_count(),\n",
    "        min_cluster_size=min_cluster_size,\n",
    "        cluster_selection_epsilon=0.01,\n",
    "        min_samples=1,\n",
    "        approx_min_span_tree=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42828efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_hotspots(imageEngine: ImageFactory, vecs: np.ndarray,\n",
    "                 data_dir: Path, plot_id: str,\n",
    "                 cluster_spec: ClusterSpec,\n",
    "                ):\n",
    "    \"\"\"Return the stable clusters from the condensed tree of connected components from the density graph\n",
    "\n",
    "    Args:\n",
    "        layouts (Optional[dict] = {}) \n",
    "        use_high_dimensional_vectors (Optional[bool] = True) \n",
    "        n_preproc_dims\n",
    "        vecs\n",
    "        umap = Used if use_high_dimensional_vectors is False\n",
    "        max_clusters\n",
    "\n",
    "    \"\"\"\n",
    "    print(timestamp(), \"Clustering data with HDBSCAN\")\n",
    "    model = get_cluster_model(cluster_spec.min_cluster_size)\n",
    "    z = model.fit(vecs)\n",
    "\n",
    "    # create a map from cluster label to image indices in cluster\n",
    "    d = defaultdict(lambda: defaultdict(list))\n",
    "    for idx, i in enumerate(z.labels_):\n",
    "        if i != -1:\n",
    "            d[i][\"images\"].append(idx)\n",
    "            d[i][\"img\"] = imageEngine[idx].filename\n",
    "            d[i][\"layout\"] = \"inception_vectors\"\n",
    "\n",
    "    # remove massive clusters\n",
    "    deletable = []\n",
    "    for i in d:\n",
    "        # find percent of images in cluster\n",
    "        image_percent = len(d[i][\"images\"]) / len(vecs)\n",
    "        # determine if image or area percent is too large\n",
    "        if image_percent > 0.5:\n",
    "            deletable.append(i)\n",
    "    for i in deletable:\n",
    "        del d[i]\n",
    "\n",
    "    # sort the clusers by size and then label the clusters\n",
    "    clusters = d.values()\n",
    "    clusters = sorted(clusters, key=lambda i: len(i[\"images\"]), reverse=True)\n",
    "    for idx, i in enumerate(clusters):\n",
    "        i[\"label\"] = f\"Cluster {idx + 1}\"\n",
    "\n",
    "    # slice off the first `max_clusters`\n",
    "    clusters = clusters[: cluster_spec.max_clusters]\n",
    "\n",
    "    # save the hotspots to disk and return the path to the saved json\n",
    "    print(timestamp(), \"Found\", len(clusters), \"hotspots\")\n",
    "    return write_json(get_json_path(data_dir, \"hotspots\", \"hotspot\", plot_id),\n",
    "                      clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8ff2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
