{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5efd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp hotspots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ece0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfc28a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import multiprocessing\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "# from hdbscan import HDBSCAN\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.cluster import HDBSCAN\n",
    "\n",
    "from clip_plot.configuration import ClusterSpec\n",
    "from clip_plot.images import ImageFactory\n",
    "from clip_plot.utils import get_json_path, timestamp, write_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2654cbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_cluster_model(min_cluster_size: int = 15):\n",
    "    \"\"\"Return model with .fit() method that can be used to cluster input vectors\n",
    "    \"\"\"\n",
    "    return HDBSCAN(\n",
    "        n_jobs=-1,\n",
    "        # core_dist_n_jobs=multiprocessing.cpu_count(),\n",
    "        min_cluster_size=min_cluster_size,\n",
    "        min_samples=1,\n",
    "        # approx_min_span_tree=False,\n",
    "        metric=\"cosine\",\n",
    "        cluster_selection_method=\"eom\",\n",
    "        alpha=1.0,\n",
    "        allow_single_cluster=False,\n",
    "        algorithm=\"brute\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42828efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_hotspots(imageEngine: ImageFactory,\n",
    "                 vecs: np.ndarray,\n",
    "                 data_dir: Path, plot_id: str,\n",
    "                 cluster_spec: ClusterSpec,\n",
    "                 layout_name: str = \"umap_base_layout\",\n",
    "                ):\n",
    "    \"\"\"Return the stable clusters from the condensed tree of connected components from the density graph\n",
    "    \"\"\"\n",
    "    print(timestamp(), \"Clustering data with HDBSCAN\")\n",
    "    model = get_cluster_model(cluster_spec.min_cluster_size)\n",
    "    # vecs = vecs / np.linalg.norm(vecs, axis=1, keepdims=True)\n",
    "    X_norm = normalize(vecs, norm=\"l2\")\n",
    "    z = model.fit(X_norm)\n",
    "\n",
    "    # create a map from cluster label to image indices in cluster\n",
    "    d = defaultdict(lambda: defaultdict(list))\n",
    "    for idx, i in enumerate(z.labels_):\n",
    "        if i != -1:\n",
    "            d[i][\"images\"].append(idx)\n",
    "            d[i][\"img\"] = imageEngine[idx].unique_name\n",
    "            d[i][\"layout\"] = layout_name\n",
    "\n",
    "    # remove massive clusters\n",
    "    deletable = []\n",
    "    for i in d:\n",
    "        # find percent of images in cluster\n",
    "        image_percent = len(d[i][\"images\"]) / len(vecs)\n",
    "        # determine if image or area percent is too large\n",
    "        if image_percent > 0.5:\n",
    "            deletable.append(i)\n",
    "    for i in deletable:\n",
    "        del d[i]\n",
    "\n",
    "    # sort the clusers by size and then label the clusters\n",
    "    clusters = d.values()\n",
    "    clusters = sorted(clusters, key=lambda i: len(i[\"images\"]), reverse=True)\n",
    "    for idx, i in enumerate(clusters):\n",
    "        i[\"label\"] = f\"Cluster {idx + 1}\"\n",
    "\n",
    "    # slice off the first `max_clusters`\n",
    "    clusters = clusters[: cluster_spec.max_clusters]\n",
    "\n",
    "    # save the hotspots to disk and return the path to the saved json\n",
    "    print(timestamp(), \"Found\", len(clusters), \"hotspots\")\n",
    "    json_path = get_json_path(data_dir, \"hotspots\", plot_id, \"hotspot\",)\n",
    "    write_json(json_path, data_dir=data_dir, obj=clusters)\n",
    "    return json_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8ff2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
