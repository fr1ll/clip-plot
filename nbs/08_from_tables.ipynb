{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp from_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `from_tables`\n",
    "\n",
    "> Get image and vector locations, and optionally metadata, from one or more table inputs\n",
    "\n",
    "- Allows you to create embeddings with any external program\n",
    "- Simplifies matching embeddings, images, and metadata to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from typing import Tuple, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def cat_tables(table_paths: list[Path]) -> pd.DataFrame:\n",
    "    '''\n",
    "    read and concatenate tables from list of paths\n",
    "    '''\n",
    "    extensions = {p.suffix.lower() for p in table_paths}\n",
    "    if extensions not in [{\".csv\"}, {\".parquet\"}]:\n",
    "        raise ValueError(f\"All tables must have same extension, either .csv or .parquet. Got: {extensions}\")\n",
    "    if extensions == {\".csv\"}:\n",
    "        dataset = [pd.read_csv(t) for t in table_paths]\n",
    "        return pd.concat(dataset, ignore_index=True)\n",
    "    elif extensions == {\".parquet\"}:\n",
    "        dataset = pq.ParquetDataset(table_paths)\n",
    "        return dataset.read().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def glob_to_tables(pattern: str) -> pd.DataFrame:\n",
    "    '''\n",
    "    expand a glob of tables, read in the tables,\n",
    "    and output as concatenated DataFrame\n",
    "    '''\n",
    "    table_paths = [Path(p) for p in glob(pattern, recursive=True)]\n",
    "    if len(table_paths) == 0:\n",
    "        raise FileNotFoundError(\"No tables matched.\")\n",
    "    return cat_tables(table_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "def test_parquet():\n",
    "    pattern = \"DELETEME_*.parquet\"\n",
    "    test_paths = [Path(pattern.replace(\"*\",str(i))) for i in range(2)]\n",
    "    for i, p in enumerate(test_paths):\n",
    "        df = pd.DataFrame({\"a\": [0,1], \"c\":[5,7], \"b\": [12,5]})\n",
    "        # parquet dataset can handle different column ordering\n",
    "        if i == 0: df.sort_index(inplace=True)\n",
    "        df.to_parquet(p)\n",
    "    g = glob_to_tables(pattern)\n",
    "    [p.unlink() for p in test_paths]\n",
    "    return g\n",
    "\n",
    "test_eq(test_parquet(), pd.DataFrame({\"a\": [0,1,0,1], \"c\": [5,7,5,7], \"b\": [12,5,12,5]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = test_parquet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def table_to_meta(table: pd.DataFrame) -> Tuple[List, List]:\n",
    "    '''convert table to metadata columns and list'''\n",
    "    # viewer expects filename column\n",
    "    table = table.rename(columns={\"image_filename\": \"filename\"})\n",
    "    meta_columns = set(table.columns) - set([\"image_path\", \"embed_path\"])\n",
    "    # convert to list as pandas does not let you index with a set\n",
    "    meta_columns = list(meta_columns)\n",
    "    df_meta = table[meta_columns]\n",
    "    return meta_columns, list(df_meta.to_dict(orient='index').values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clipplot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
