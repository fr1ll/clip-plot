{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp from_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/willsa/git/clip-plot/.venv/lib/python3.10/site-packages/nbdev/doclinks.py:20: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources,importlib\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `from_tables`\n",
    "\n",
    "> Get image and vector locations, and optionally metadata, from one or more table inputs\n",
    "\n",
    "- Allows you to create embeddings with any external program\n",
    "- Simplifies matching embeddings, images, and metadata to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from typing import Tuple, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def glob_to_tables(pattern: str) -> pd.DataFrame:\n",
    "    '''\n",
    "    expand a glob of tables, read in the tables,\n",
    "    and output as concatenated DataFrame\n",
    "    '''\n",
    "    table_paths = [Path(p) for p in glob(pattern, recursive=True)]\n",
    "    if len(table_paths) == 0: raise FileNotFoundError(\"No tables matched.\")\n",
    "\n",
    "    extensions = {p.suffix for p in table_paths}\n",
    "    if extensions == {\".csv\"}:\n",
    "        dataset = [pd.read_csv(t) for t in table_paths]\n",
    "        return pd.concat(dataset, ignore_index=True)\n",
    "    elif extensions == {\".parquet\"}:\n",
    "        dataset = pq.ParquetDataset(table_paths)\n",
    "        return dataset.read().to_pandas()\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported table extensions: {extensions}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "def test_parquet():\n",
    "    pattern = \"DELETEME_*.parquet\"\n",
    "    test_paths = [Path(pattern.replace(\"*\",str(i))) for i in range(2)]\n",
    "    for i, p in enumerate(test_paths):\n",
    "        df = pd.DataFrame({\"a\": [0,1], \"c\":[5,7], \"b\": [12,5]})\n",
    "        # parquet dataset can handle different column ordering\n",
    "        if i == 0: df.sort_index(inplace=True)\n",
    "        df.to_parquet(p)\n",
    "    g = glob_to_tables(pattern)\n",
    "    [p.unlink() for p in test_paths]\n",
    "    return g\n",
    "\n",
    "test_eq(test_parquet(), pd.DataFrame({\"a\": [0,1,0,1], \"c\": [5,7,5,7], \"b\": [12,5,12,5]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = test_parquet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def table_to_meta(table: pd.DataFrame) -> Tuple[List, List]:\n",
    "    '''convert table to metadata columns and list'''\n",
    "    # viewer expects filename column\n",
    "    table = table.rename(columns={\"image_filename\": \"filename\"})\n",
    "    meta_columns = set(table.columns) - set([\"image_path\", \"embed_path\"])\n",
    "    # convert to list as pandas does not let you index with a set\n",
    "    meta_columns = list(meta_columns)\n",
    "    df_meta = table[meta_columns]\n",
    "    return meta_columns, list(df_meta.to_dict(orient='index').values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
