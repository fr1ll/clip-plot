{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp from_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from fastcore.test import test_eq"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `from_tables`\n",
    "\n",
    "> Get image and vector locations, and optionally metadata, from one or more table inputs\n",
    "\n",
    "- Allows you to create embeddings with any external program\n",
    "- Simplifies matching embeddings, images, and metadata to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "from pathlib import Path\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def cat_tables(table_paths: list[Path]) -> pd.DataFrame:\n",
    "    '''\n",
    "    read and concatenate tables from list of paths\n",
    "    '''\n",
    "    extensions = {p.suffix.lower() for p in table_paths}\n",
    "    if extensions not in [{\".csv\"}, {\".parquet\"}]:\n",
    "        raise ValueError(f\"All tables must have same extension, either .csv or .parquet. Got: {extensions}\")\n",
    "    if extensions == {\".csv\"}:\n",
    "        dataset = [pd.read_csv(t) for t in table_paths]\n",
    "        return pd.concat(dataset, ignore_index=True)\n",
    "    elif extensions == {\".parquet\"}:\n",
    "        dataset = pq.ParquetDataset(table_paths)\n",
    "        return dataset.read().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def glob_to_tables(pattern: str) -> pd.DataFrame:\n",
    "    '''\n",
    "    expand a glob of tables, read in the tables,\n",
    "    and output as concatenated DataFrame\n",
    "    '''\n",
    "    table_paths = [Path(p) for p in glob(pattern, recursive=True)]\n",
    "    if len(table_paths) == 0:\n",
    "        raise FileNotFoundError(\"No tables matched.\")\n",
    "    return cat_tables(table_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "def test_parquet():\n",
    "    pattern = \"DELETEME_*.parquet\"\n",
    "    test_paths = [Path(pattern.replace(\"*\",str(i))) for i in range(2)]\n",
    "    for i, p in enumerate(test_paths):\n",
    "        df = pd.DataFrame({\"a\": [0,1], \"c\":[5,7], \"b\": [12,5]})\n",
    "        # parquet dataset can handle different column ordering\n",
    "        if i == 0:\n",
    "            df = df.sort_index()\n",
    "        df.to_parquet(p)\n",
    "    g = glob_to_tables(pattern)\n",
    "    [p.unlink() for p in test_paths]\n",
    "    return g\n",
    "\n",
    "test_eq(test_parquet(), pd.DataFrame({\"a\": [0,1,0,1], \"c\": [5,7,5,7], \"b\": [12,5,12,5]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = test_parquet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def table_to_meta(table: pd.DataFrame) -> tuple[list, list]:\n",
    "    '''convert table to metadata columns and list'''\n",
    "    # viewer expects filename column\n",
    "    table = table.rename(columns={\"image_filename\": \"filename\"})\n",
    "    meta_columns = set(table.columns) - set(\"image_path\", \"hidden_vectors_path\")\n",
    "    # convert to list as pandas does not let you index with a set\n",
    "    meta_columns = list(meta_columns)\n",
    "    df_meta = table[meta_columns]\n",
    "    return meta_columns, list(df_meta.to_dict(orient='index').values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
