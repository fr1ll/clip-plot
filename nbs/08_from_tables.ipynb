{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp from_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `from_tables`\n",
    "\n",
    "> Get image and vector locations, and optionally metadata, from one or more table inputs\n",
    "\n",
    "- Allows you to create embeddings with any external program\n",
    "- Simplifies matching embeddings, images, and metadata to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def glob_to_tables(pattern: str) -> pd.DataFrame:\n",
    "    '''\n",
    "    expand a glob of tables, read in the tables,\n",
    "    and output as concatenated DataFrame\n",
    "    '''\n",
    "    table_paths = list(Path().glob(pattern))\n",
    "    if len(table_paths) == 0: raise FileNotFoundError(\"No tables matched.\")\n",
    "\n",
    "    extensions = {p.suffix for p in table_paths}\n",
    "    if extensions == {\".csv\"}:\n",
    "        dataset = [pd.read_csv(t) for t in table_paths]\n",
    "        return pd.concat(dataset, ignore_index=True)\n",
    "    elif extensions == {\".parquet\"}:\n",
    "        dataset = pq.ParquetDataset(table_paths)\n",
    "        return dataset.read().to_pandas()\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported table extensions: {extensions}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "def test_parquet():\n",
    "    pattern = \"DELETEME_*.parquet\"\n",
    "    test_paths = [Path(pattern.replace(\"*\",str(i))) for i in range(2)]\n",
    "    for p in test_paths:\n",
    "        df = pd.DataFrame({\"a\": [0,1], \"b\":[5,7]})\n",
    "        df.to_parquet(p)\n",
    "    g = glob_to_tables(pattern)\n",
    "    [p.unlink() for p in test_paths]\n",
    "    return g\n",
    "\n",
    "    test_eq(test_parquet(), pd.DataFrame({\"a\": [0,1,0,1], \"b\": [5,7,5,7]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
