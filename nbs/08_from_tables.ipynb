{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp from_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from fastcore.test import test_eq"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `from_tables`\n",
    "\n",
    "> Get image and vector locations, and optionally metadata, from one or more table inputs\n",
    "\n",
    "- Allows you to create embeddings with any external program\n",
    "- Simplifies matching embeddings, images, and metadata to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def cat_tables(table_paths: list[Path]) -> pl.DataFrame:\n",
    "    '''\n",
    "    read and concatenate tables from list of paths\n",
    "    '''\n",
    "    extensions = {p.suffix.lower() for p in table_paths}\n",
    "    if extensions not in [{\".csv\"}, {\".parquet\"}]:\n",
    "        raise ValueError(f\"All tables must have same extension, either .csv or .parquet. Got: {extensions}\")\n",
    "    if extensions == {\".csv\"}:\n",
    "        return pl.concat((pl.read_csv(t) for t in table_paths), how=\"diagonal_relaxed\")\n",
    "    elif extensions == {\".parquet\"}:\n",
    "        return pl.concat((pl.read_parquet(t) for t in table_paths), how=\"diagonal_relaxed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def glob_to_tables(pattern: str) -> pd.DataFrame:\n",
    "    '''\n",
    "    expand a glob of tables, read in the tables,\n",
    "    and output as concatenated DataFrame\n",
    "    '''\n",
    "    table_paths = [Path(p) for p in glob(pattern, recursive=True)]\n",
    "    if len(table_paths) == 0:\n",
    "        raise FileNotFoundError(\"No tables matched.\")\n",
    "    return cat_tables(table_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "def test_parquet():\n",
    "    pattern = \"DELETEME_*.parquet\"\n",
    "    test_paths = [Path(pattern.replace(\"*\",str(i))) for i in range(2)]\n",
    "    for i, p in enumerate(test_paths):\n",
    "        df = pl.DataFrame({\"a\": [0,1], \"c\":[5,7], \"b\": [12,5]})\n",
    "        # change column ordering to test concatenation\n",
    "        if i == 0:\n",
    "            df = df.select([\"a\", \"b\", \"c\"])\n",
    "        df.write_parquet(p)\n",
    "    g = glob_to_tables(pattern)\n",
    "    [p.unlink() for p in test_paths]\n",
    "    return g\n",
    "\n",
    "test_eq(test_parquet(), pl.DataFrame({\"a\": [0,1,0,1], \"b\": [12,5,12,5], \"c\": [5,7,5,7]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def table_to_meta(table: pl.DataFrame) -> tuple[list, list]:\n",
    "    '''convert table to metadata columns and list'''\n",
    "    # viewer expects filename column\n",
    "    table = table.rename({\"image_filename\": \"filename\"})\n",
    "    meta_columns = set(table.columns) - {\"image_path\", \"hidden_vectors\"}\n",
    "    # convert to list as pandas does not let you index with a set\n",
    "    meta_columns = list(meta_columns)\n",
    "    df_meta = table[meta_columns]\n",
    "    return meta_columns, df_meta.to_dicts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
