{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp clip_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and setup\n",
    "\n",
    "### Unconditional imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "from __future__ import division\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# print separately that we're loading dependencies, as this can take a while\n",
    "# and we want to give immediate feedback the program is starting\n",
    "from clip_plot.utils import timestamp\n",
    "print(timestamp(), \"Beginning to load dependencies\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "from fastcore.all import *\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from clip_plot import utils\n",
    "from clip_plot.utils import get_version, FILE_NAME\n",
    "from clip_plot.embeddings import get_inception_vectors\n",
    "from clip_plot.metadata import get_manifest, write_metadata\n",
    "\n",
    "from clip_plot.images import write_images, create_atlas_files, ImageFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from shutil import rmtree\n",
    "from pathlib import Path\n",
    "from typing import Optional, List, Union, Tuple\n",
    "import uuid\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image processing imports\n",
    "\n",
    "Note that I have removed the \"copy-web-only\" conditional import path for now\n",
    "\n",
    "`nbdev` does not like cells to have cells to have code and imports in the same cell:\n",
    "\n",
    "https://nbdev.fast.ai/getting_started.html#q-what-is-the-warning-found-a-cell-containing-mix-of-imports-and-computations.-please-use-separate-cells\n",
    "\n",
    "I think this may mean we don't get to do conditional imports. If we find a code path that really should have conditional imports, we can see if there is a workaround. For now, I don't feel \"copy web only\" is a very important functionality to keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional install imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "DEFAULTS = {\n",
    "    \"images\": None,\n",
    "    \"embeds\": None,\n",
    "    \"meta_dir\": None,\n",
    "    \"out_dir\": \"output\",\n",
    "    \"max_images\": None,\n",
    "    \"use_cache\": True,\n",
    "    \"encoding\": \"utf8\",\n",
    "    \"cluster_preproc_dims\": -1,\n",
    "    \"min_cluster_size\": 20,\n",
    "    \"max_clusters\": 10,\n",
    "    \"atlas_size\": 2048,\n",
    "    \"cell_size\": 32,\n",
    "    \"lod_cell_height\": 128, # Why is not in parser?\n",
    "    \"n_neighbors\": [15],\n",
    "    \"min_dist\": [0.01],\n",
    "    \"umap_on_full_dims\": False,\n",
    "    \"n_components\": 2,\n",
    "    \"metric\": \"correlation\",\n",
    "    \"pointgrid_fill\": 0.05,\n",
    "    \"gzip\": False,\n",
    "    \"min_size\": 100,\n",
    "    \"min_score\": 0.3,\n",
    "    \"min_vertices\": 18,\n",
    "    \"plot_id\": str(uuid.uuid1()),\n",
    "    \"seed\": 24,\n",
    "    \"n_clusters\": 12,\n",
    "    \"geojson\": None,\n",
    "}\n",
    "\n",
    "# handle truncated images in PIL (managed by Pillow)\n",
    "PILLoadTruncated  = True\n",
    "\n",
    "\"\"\"\n",
    "NB: Keras Image class objects return image.size as w,h\n",
    "    Numpy array representations of images return image.shape as h,w,c\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Entry\n",
    "\n",
    "`process_images` will kick off all the main functions for the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "def get_clip_plot_root() -> Path:\n",
    "    # ipython doesn't have __file__ attribute\n",
    "    if in_ipython():\n",
    "        return Path(utils.__file__).parents[1]\n",
    "    else:\n",
    "        return Path(__file__).parents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def process_images(imageEngine, **kwargs):\n",
    "    \"\"\"\n",
    "    Main method for processing user images and metadata\n",
    "    It would be nice to list out the image processing steps before getting started\n",
    "    \"\"\"\n",
    "    kwargs = preprocess_kwargs(**kwargs)\n",
    "    print(timestamp(), \"Starting image processing pipeline.\")\n",
    "\n",
    "    copy_web_assets(out_dir=kwargs['out_dir'])\n",
    "    if kwargs[\"copy_web_only\"]:\n",
    "        print(timestamp(), \"Done!\")\n",
    "        sys.exit()\n",
    "    \n",
    "    np.random.seed(kwargs[\"seed\"])\n",
    "    kwargs[\"out_dir\"] = os.path.join(kwargs[\"out_dir\"], \"data\")\n",
    "    write_metadata(imageEngine, kwargs[\"gzip\"], kwargs[\"encoding\"])\n",
    "    \n",
    "    kwargs[\"atlas_dir\"] = create_atlas_files(imageEngine, kwargs[\"plot_id\"], kwargs[\"use_cache\"])\n",
    "    \n",
    "    kwargs[\"vecs\"] = get_inception_vectors(imageEngine, **kwargs)\n",
    "    get_manifest(imageEngine, **kwargs)\n",
    "    write_images(imageEngine)\n",
    "    print(timestamp(), \"Done!\")\n",
    "\n",
    "\n",
    "def preprocess_kwargs(**kwargs):\n",
    "    \"\"\"Preprocess incoming key word arguments\n",
    "    Converts n_neighbors and min_dist arguments into a list\n",
    "\n",
    "    Args:\n",
    "        n_neighbors (int, list[int], default = [15])\n",
    "        min_dist (int, list[int], default = [0.01])\n",
    "\n",
    "    Notes:\n",
    "        Convenient hook for preprocessing arguments\n",
    "    \n",
    "    \"\"\"\n",
    "    for i in [\"n_neighbors\", \"min_dist\"]:\n",
    "        if not isinstance(kwargs[i], list):\n",
    "            kwargs[i] = [kwargs[i]]\n",
    "    return kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def copy_web_assets(out_dir: str) -> None:\n",
    "    \"\"\"Copy the /web directory from the clipplot source to the users cwd.\n",
    "    Copies version number into assets.\n",
    "    \n",
    "    Args: \n",
    "        out_dir (str): directory to copy web assets\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    copy_root_dir = get_clip_plot_root()\n",
    "    src = copy_root_dir / \"clip_plot/web\"\n",
    "\n",
    "    # resolve will handle cases with ../ in the path\n",
    "    dest = Path.cwd() / Path(out_dir).resolve()\n",
    "    utils.copytree_agnostic(src.as_posix(), dest.as_posix())\n",
    "\n",
    "    # write version numbers into output\n",
    "    for i in [\"index.html\", os.path.join(\"assets\", \"js\", \"tsne.js\")]:\n",
    "        path = os.path.join(dest, i)\n",
    "        with open(path, \"r\") as f:\n",
    "            f = f.read().replace(\"VERSION_NUMBER\", get_version())\n",
    "            with open(path, \"w\") as out:\n",
    "                out.write(f)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carlo's Test Functions\n",
    "# Need to remove later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "copy_root_dir = get_clip_plot_root()\n",
    "\n",
    "def test_iiif(config):\n",
    "    test_images = copy_root_dir/\"tests/IIIF_examples/iif_example.txt\"\n",
    "    test_out_dir = copy_root_dir/\"tests/smithsonian_butterflies_10/output_test_temp\"\n",
    "\n",
    "    if Path(test_out_dir).exists():\n",
    "        rmtree(test_out_dir)\n",
    "\n",
    "    config[\"images\"] = test_images.as_posix()\n",
    "    config[\"out_dir\"] = test_out_dir.as_posix()\n",
    "    config[\"plot_id\"] = \"test_diff\"\n",
    "\n",
    "    return config\n",
    "\n",
    "\n",
    "def test_butterfly_duplicate(config):\n",
    "    test_images = copy_root_dir/\"tests/smithsonian_butterflies_10/jpgs_duplicates/**/*.jpg\"\n",
    "    test_out_dir = copy_root_dir/\"tests/smithsonian_butterflies_10/output_test_temp\"\n",
    "    meta_dir = copy_root_dir/\"tests/smithsonian_butterflies_10/meta_data/good_meta.csv\"\n",
    "    if Path(test_out_dir).exists():\n",
    "        rmtree(test_out_dir)\n",
    "\n",
    "    config[\"images\"] = test_images.as_posix()\n",
    "    config[\"out_dir\"] = test_out_dir.as_posix()\n",
    "    config[\"meta_dir\"] = meta_dir.as_posix()\n",
    "    config[\"plot_id\"] = \"test_diff\"\n",
    "\n",
    "    return config\n",
    "\n",
    "\n",
    "def test_butterfly(config):\n",
    "    test_images = copy_root_dir/\"tests/smithsonian_butterflies_10/jpgs/*.jpg\"\n",
    "    test_out_dir = copy_root_dir/\"tests/smithsonian_butterflies_10/output_test_temp\"\n",
    "    meta_dir = copy_root_dir/\"tests/smithsonian_butterflies_10/meta_data/good_meta.csv\"\n",
    "    if Path(test_out_dir).exists():\n",
    "        rmtree(test_out_dir)\n",
    "\n",
    "    config[\"images\"] = test_images.as_posix()\n",
    "    config[\"out_dir\"] = test_out_dir.as_posix()\n",
    "    config[\"meta_dir\"] = meta_dir.as_posix()\n",
    "    config[\"plot_id\"] = \"test_diff\"\n",
    "    \n",
    "    config[\"test_mode\"] = True\n",
    "\n",
    "    return config\n",
    "\n",
    "\n",
    "def test_butterfly_missing_meta(config):\n",
    "    test_images = copy_root_dir/\"tests/smithsonian_butterflies_10/jpgs/*.jpg\"\n",
    "    test_out_dir = copy_root_dir/\"tests/smithsonian_butterflies_10/output_test_temp\"\n",
    "    meta_dir = copy_root_dir/\"tests/smithsonian_butterflies_10/meta_data/meta_missing_entry.csv\"\n",
    "    if Path(test_out_dir).exists():\n",
    "        rmtree(test_out_dir)\n",
    "\n",
    "    config[\"images\"] = test_images.as_posix()\n",
    "    config[\"out_dir\"] = test_out_dir.as_posix()\n",
    "    config[\"meta_dir\"] = meta_dir.as_posix()\n",
    "    config[\"plot_id\"] = \"test_diff\"\n",
    "\n",
    "    return config\n",
    "\n",
    "\n",
    "def test_no_meta_dir(config):\n",
    "    test_images = copy_root_dir/\"tests/smithsonian_butterflies_10/jpgs/*.jpg\"\n",
    "    test_out_dir = copy_root_dir/\"tests/smithsonian_butterflies_10/output_test_temp\"\n",
    "    if Path(test_out_dir).exists():\n",
    "        rmtree(test_out_dir)\n",
    "\n",
    "    config[\"images\"] = test_images.as_posix()\n",
    "    config[\"out_dir\"] = test_out_dir.as_posix()\n",
    "    config[\"plot_id\"] = \"test_diff\"\n",
    "\n",
    "    return config\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse the command-line arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@call_parse\n",
    "def project_imgs(images:Param(type=str,\n",
    "                        help=\"path or glob of images to process\"\n",
    "                        )=DEFAULTS[\"images\"],\n",
    "                embeds:Param(type=str,\n",
    "                        help=\"path or glob of embeddings to process (must match images folder/file structure)\"\n",
    "                        )=DEFAULTS[\"embeds\"],\n",
    "                metadata:Param(type=str,\n",
    "                        help=\"path to a csv or glob of JSON files with image metadata (see readme for format)\"\n",
    "                        )=DEFAULTS[\"meta_dir\"],\n",
    "                max_images:Param(type=int,\n",
    "                        help=\"maximum number of images to process\"\n",
    "                        )=DEFAULTS[\"max_images\"],\n",
    "                use_cache:Param(type=store_true,\n",
    "                        help=\"given inputs identical to prior inputs, load outputs from cache\"\n",
    "                        )=DEFAULTS[\"use_cache\"],\n",
    "                encoding:Param(type=str,\n",
    "                        help=\"the encoding of input metadata\"\n",
    "                        )=DEFAULTS[\"encoding\"],\n",
    "                cluster_preproc_dims:Param(type=int,\n",
    "                        help=\"number of dims to reduce to prior to clustering. -1 means don't reduce\",\n",
    "                        required=False\n",
    "                        )=DEFAULTS[\"cluster_preproc_dims\"],\n",
    "                min_cluster_size:Param(type=int,\n",
    "                        help=\"the minimum number of images in a cluster\",\n",
    "                        required=False\n",
    "                        )=DEFAULTS[\"min_cluster_size\"],\n",
    "                max_clusters:Param(type=int,\n",
    "                        help=\"the maximum number of clusters to return\",\n",
    "                        required=False\n",
    "                        )=DEFAULTS[\"max_clusters\"],\n",
    "                out_dir:Param(type=str,\n",
    "                        help=\"the directory to which outputs will be saved\",\n",
    "                        required=False\n",
    "                        )=DEFAULTS[\"out_dir\"],\n",
    "                cell_size:Param(type=int,\n",
    "                        help=\"the size of atlas cells in px\",\n",
    "                        required=False\n",
    "                        )=DEFAULTS[\"cell_size\"],\n",
    "                n_neighbors:Param(type=int,\n",
    "                        nargs=\"+\",\n",
    "                        help=\"the n_neighbors arguments for UMAP\"\n",
    "                        )=DEFAULTS[\"n_neighbors\"],\n",
    "                min_dist:Param(type=float,\n",
    "                        nargs=\"+\",\n",
    "                        help=\"the min_dist arguments for UMAP\"\n",
    "                        )=DEFAULTS[\"min_dist\"],\n",
    "                umap_on_full_dims:Param(type=store_true,\n",
    "                        help=\"perform PCA prior to main dimensionality reduction\"\n",
    "                        )=DEFAULTS[\"umap_on_full_dims\"],\n",
    "                n_components:Param(type=int,\n",
    "                        help=\"the n_components argument for UMAP\"\n",
    "                        )=DEFAULTS[\"n_components\"],\n",
    "                metric:Param(type=str,\n",
    "                        help=\"the metric argument for umap\"\n",
    "                        )=DEFAULTS[\"metric\"],\n",
    "                pointgrid_fill:Param(type=float,\n",
    "                        help=\"float 0:1 that determines sparsity of jittered distributions (lower means more sparse)\"\n",
    "                        )=DEFAULTS[\"pointgrid_fill\"],\n",
    "                copy_web_only:Param(type=store_true,\n",
    "                        help=\"update ./output/assets without reprocessing data\"\n",
    "                        )=False,\n",
    "                min_size:Param(type=float,\n",
    "                        help=\"min size of cropped images\"\n",
    "                        )=DEFAULTS[\"min_size\"],\n",
    "                gzip:Param(type=store_true,\n",
    "                        help=\"save outputs with gzip compression\"\n",
    "                        )=False,\n",
    "                shuffle:Param(type=store_true,\n",
    "                        help=\"shuffle the input images before data processing begins\"\n",
    "                        )=False,\n",
    "                plot_id:Param(type=str,\n",
    "                        help=\"unique id for a plot; useful for resuming processing on a started plot\"\n",
    "                        )=DEFAULTS[\"plot_id\"],\n",
    "                seed:Param(type=int, help=\"seed for random processes\"\n",
    "                           )=DEFAULTS[\"seed\"],\n",
    "                n_clusters:Param(type=int,\n",
    "                        help=\"number of clusters if using kmeans\"\n",
    "                        )=DEFAULTS[\"n_clusters\"],\n",
    "                geojson:Param(type=str,\n",
    "                        help=\"path to a GeoJSON file with shapes to be rendered on a map\"\n",
    "                        )=DEFAULTS[\"geojson\"]\n",
    "                ):\n",
    "                \"Convert a folder of images into a clip-plot visualization\"\n",
    "\n",
    "                # grab local variables as configuration dict\n",
    "                config = dict(locals())\n",
    "\n",
    "                # some parameters exist in DEFAULTS but not in the function signature\n",
    "                default_only_keys = set(set(DEFAULTS.keys() - config.keys()))\n",
    "                default_only = {k:DEFAULTS[k] for k in default_only_keys}\n",
    "                config.update(default_only)\n",
    "\n",
    "\n",
    "                if in_ipython() and config[\"images\"] == None:\n",
    "                        print(\"Clip-plot is being run from ipython\")\n",
    "                        # at least for now, this means we're in testing mode.\n",
    "                        # TODO: pass explicit \"test_mode\" flag\n",
    "                        config = test_butterfly(config)\n",
    "\n",
    "                options = {\n",
    "                        'shuffle': config['shuffle'], \n",
    "                        'seed': config['seed'], \n",
    "                        'max_images': config['max_images'], \n",
    "                        'atlas_size': config['atlas_size'], \n",
    "                        'cell_size': config['cell_size'], \n",
    "                        'lod_cell_height': config['lod_cell_height'], \n",
    "                        'validate': True, \n",
    "                }\n",
    "\n",
    "                out_dir = os.path.join(config[\"out_dir\"], \"data\")\n",
    "                imageEngine = ImageFactory(config['images'], out_dir, config['meta_dir'], options)\n",
    "                \n",
    "                process_images(imageEngine, **config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    project_imgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
