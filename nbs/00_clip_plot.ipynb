{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp clip_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and setup\n",
    "\n",
    "### Unconditional imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from __future__ import division\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "from fastcore.all import *\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from clip_plot import utils\n",
    "from clip_plot.layouts import get_layouts\n",
    "from clip_plot.utils import clean_filename, timestamp\n",
    "from clip_plot.utils import  get_version, FILE_NAME\n",
    "from clip_plot.embeddings import get_inception_vectors\n",
    "from clip_plot.metadata import get_manifest, write_metadata, get_metadata_list\n",
    "from clip_plot.images import PILLoadTruncated, save_image, write_images, Image, get_image_paths, create_atlas_files\n",
    "from clip_plot.images import ImageFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from shutil import rmtree\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "from typing import Optional, List, Union, Tuple\n",
    "import uuid\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image processing imports\n",
    "\n",
    "Note that I have removed the \"copy-web-only\" conditional import path for now\n",
    "\n",
    "`nbdev` does not like cells to have cells to have code and imports in the same cell:\n",
    "\n",
    "https://nbdev.fast.ai/getting_started.html#q-what-is-the-warning-found-a-cell-containing-mix-of-imports-and-computations.-please-use-separate-cells\n",
    "\n",
    "I think this may mean we don't get to do conditional imports. If we find a code path that really should have conditional imports, we can see if there is a workaround. For now, I don't feel \"copy web only\" is a very important functionality to keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional install imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "DEFAULTS = {\n",
    "    \"images\": None,\n",
    "    \"embeds\": None,\n",
    "    \"meta_dir\": None,\n",
    "    \"out_dir\": \"output\",\n",
    "    \"max_images\": None,\n",
    "    \"use_cache\": True,\n",
    "    \"encoding\": \"utf8\",\n",
    "    \"min_cluster_size\": 20,\n",
    "    \"max_clusters\": 10,\n",
    "    \"atlas_size\": 2048,\n",
    "    \"cell_size\": 32,\n",
    "    \"lod_cell_height\": 128, # Why is not in parser?\n",
    "    \"n_neighbors\": [15],\n",
    "    \"min_dist\": [0.01],\n",
    "    \"n_components\": 2,\n",
    "    \"metric\": \"correlation\",\n",
    "    \"pointgrid_fill\": 0.05,\n",
    "    \"gzip\": False,\n",
    "    \"min_size\": 100,\n",
    "    \"min_score\": 0.3,\n",
    "    \"min_vertices\": 18,\n",
    "    \"plot_id\": str(uuid.uuid1()),\n",
    "    \"seed\": 24,\n",
    "    \"n_clusters\": 12,\n",
    "    \"geojson\": None,\n",
    "}\n",
    "\n",
    "# handle truncated images in PIL (managed by Pillow)\n",
    "PILLoadTruncated  = True\n",
    "\n",
    "\"\"\"\n",
    "NB: Keras Image class objects return image.size as w,h\n",
    "    Numpy array representations of images return image.shape as h,w,c\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Entry\n",
    "\n",
    "`process_images` will kick off all the main functions for the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "def get_clip_plot_root() -> Path:\n",
    "    # ipython doesn't have __file__ attribute\n",
    "    if in_ipython():\n",
    "        return Path(utils.__file__).parents[1]\n",
    "    else:\n",
    "        return Path(__file__).parents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "copy_root_dir = get_clip_plot_root()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def process_images(imageEngine, **kwargs):\n",
    "    \"\"\"Main method for processing user images and metadata\"\"\"\n",
    "    kwargs = preprocess_kwargs(**kwargs)\n",
    "\n",
    "    copy_web_assets(out_dir=kwargs['out_dir'])\n",
    "    if kwargs[\"copy_web_only\"]:\n",
    "        print(timestamp(), \"Done!\")\n",
    "        sys.exit()\n",
    "    \n",
    "    np.random.seed(kwargs[\"seed\"])\n",
    "    kwargs[\"out_dir\"] = os.path.join(kwargs[\"out_dir\"], \"data\")\n",
    "    # kwargs[\"image_paths\"], kwargs[\"metadata\"] = filter_images(**kwargs)\n",
    "    write_metadata(imageEngine, kwargs[\"gzip\"], kwargs[\"encoding\"])\n",
    "    \n",
    "    kwargs[\"atlas_dir\"] = create_atlas_files(imageEngine, **kwargs)\n",
    "    kwargs[\"vecs\"] = get_inception_vectors(imageEngine, **kwargs)\n",
    "    get_manifest(imageEngine, **kwargs)\n",
    "    imageEngine.write_images()\n",
    "    print(timestamp(), \"Done!\")\n",
    "\n",
    "\n",
    "def preprocess_kwargs(**kwargs):\n",
    "    \"\"\"Preprocess incoming key word arguments\n",
    "    Converts n_neighbors and min_dist arguments into a list\n",
    "\n",
    "    Args:\n",
    "        n_neighbors (int, list[int], default = [15])\n",
    "        min_dist (int, list[int], default = [0.01])\n",
    "\n",
    "    Notes:\n",
    "        Convenient hook for preprocessing arguments\n",
    "    \n",
    "    \"\"\"\n",
    "    for i in [\"n_neighbors\", \"min_dist\"]:\n",
    "        if not isinstance(kwargs[i], list):\n",
    "            kwargs[i] = [kwargs[i]]\n",
    "    return kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def copy_web_assets(out_dir: str) -> None:\n",
    "    \"\"\"Copy the /web directory from the clipplot source to the users cwd.\n",
    "    Copies version number into assets.\n",
    "    \n",
    "    Args: \n",
    "        out_dir (str): directory to copy web assets\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    copy_root_dir = get_clip_plot_root()\n",
    "    src = copy_root_dir / \"clip_plot/web\"\n",
    "\n",
    "    # resolve will handle cases with ../ in the path\n",
    "    dest = Path.cwd() / Path(out_dir).resolve()\n",
    "    utils.copytree_agnostic(src.as_posix(), dest.as_posix())\n",
    "\n",
    "    # write version numbers into output\n",
    "    for i in [\"index.html\", os.path.join(\"assets\", \"js\", \"tsne.js\")]:\n",
    "        path = os.path.join(dest, i)\n",
    "        with open(path, \"r\") as f:\n",
    "            f = f.read().replace(\"VERSION_NUMBER\", get_version())\n",
    "            with open(path, \"w\") as out:\n",
    "                out.write(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def filter_images(**kwargs):\n",
    "    \"\"\"Main method for filtering images given user metadata (if provided)\n",
    "\n",
    "    -Validate image:\n",
    "        Loading (done by stream_images and Images)\n",
    "        Size\n",
    "        resizing\n",
    "        oblong\n",
    "\n",
    "    -Compare against metadata\n",
    "\n",
    "    \n",
    "    Args:\n",
    "        images (str): Directory location of images.\n",
    "        out_dir (str): Output directory.\n",
    "        shuffle (Optional[bool], default = False): Shuffle image order\n",
    "        seed (int): Seed for random generator\n",
    "        max_images (Union[bool,int]): Maximum number of images\n",
    "        atlas_size (int, default = 2048)\n",
    "        cell_size (int, default = 32)\n",
    "        lod_cell_height (int, default = 128)\n",
    "        meta_dir (str): Directory of image metadata\n",
    "\n",
    "    Returns:\n",
    "        images (list[str])\n",
    "        metadata (list[dict])\n",
    "\n",
    "    Notes:\n",
    "        Assumes 'filename' is provided in metadata\n",
    "        Convoluted compiling of metadata\n",
    "        Should All Validation should belong to Image class?\n",
    "        Need to split function\n",
    "    \"\"\"\n",
    "    # validate that input image names are unique\n",
    "    image_paths = get_image_paths(images=kwargs[\"images\"], out_dir=kwargs[\"out_dir\"])\n",
    "    image_names = list(map(clean_filename,image_paths))\n",
    "    duplicates = set([x for x in image_names if image_names.count(x) > 1])\n",
    "\n",
    "    if duplicates:\n",
    "        raise Exception(\n",
    "            \"\"\"Image filenames should be unique, but the following \n",
    "            filenames are duplicated\\n{}\"\"\".format(\"\\n\".join(duplicates)))\n",
    "    \n",
    "    # optionally shuffle the image_paths\n",
    "    if kwargs.get(\"shuffle\", False):\n",
    "        print(timestamp(), \"Shuffling input images\")\n",
    "        random.Random(kwargs[\"seed\"]).shuffle(image_paths)\n",
    "    else:\n",
    "        image_paths = sorted(image_paths)\n",
    "\n",
    "    # Optionally limit the number of images in image_paths\n",
    "    if kwargs.get(\"max_images\", False):\n",
    "        image_paths = image_paths[: kwargs[\"max_images\"]]        \n",
    "\n",
    "    # process and filter the images\n",
    "    filtered_image_paths = {}\n",
    "    oblong_ratio = kwargs[\"atlas_size\"] / kwargs[\"cell_size\"]\n",
    "\n",
    "    print(timestamp(), \"Validating input images\")\n",
    "    for img in tqdm(Image.stream_images(image_paths=image_paths), total=len(image_paths)):\n",
    "        valid, msg = img.valid(lod_cell_height=kwargs[\"lod_cell_height\"], oblong_ratio=oblong_ratio) \n",
    "        if valid is True:\n",
    "            filtered_image_paths[img.path] = img.filename\n",
    "        else:\n",
    "            print(timestamp(), msg)\n",
    "\n",
    "    # if there are no remaining images, throw an error\n",
    "    if len(filtered_image_paths) == 0:\n",
    "        raise Exception(\"No images were found! Please check your input image glob.\")\n",
    "\n",
    "    # handle the case user provided no metadata\n",
    "    if not kwargs.get(\"meta_dir\", False):\n",
    "        return [list(filtered_image_paths.keys()), []]\n",
    "\n",
    "    # handle user metadata: retain only records with image and metadata\n",
    "    metaList = get_metadata_list(meta_dir=kwargs['meta_dir'])\n",
    "    metaDict = {clean_filename(i.get(FILE_NAME, \"\")): i for i in metaList}\n",
    "    meta_bn = set(metaDict.keys())\n",
    "    img_bn = set(filtered_image_paths.values())\n",
    "\n",
    "    # identify images with metadata and those without metadata\n",
    "    meta_present = img_bn.intersection(meta_bn)\n",
    "    meta_missing = list(img_bn - meta_bn)\n",
    "\n",
    "    # notify the user of images that are missing metadata\n",
    "    if meta_missing:\n",
    "        print(\n",
    "            timestamp(),\n",
    "            \" ! Some images are missing metadata:\\n  -\",\n",
    "            \"\\n  - \".join(meta_missing[:10]),\n",
    "        )\n",
    "        if len(meta_missing) > 10:\n",
    "            print(timestamp(), \" ...\", len(meta_missing) - 10, \"more\")\n",
    "\n",
    "        if os.path.exists(kwargs['out_dir']) is False:\n",
    "            os.makedirs(kwargs['out_dir'])\n",
    "            \n",
    "        missing_dir = os.path.join(kwargs['out_dir'],\"missing-metadata.txt\")\n",
    "        with open(missing_dir, \"w\") as out:\n",
    "            out.write(\"\\n\".join(meta_missing))\n",
    "\n",
    "    if not meta_present:\n",
    "        raise Exception( f\"\"\"No image has matching metadata. Check if '{FILE_NAME}' key was provided in metadata files\"\"\")\n",
    "\n",
    "    # get the sorted lists of images and metadata\n",
    "    images = []\n",
    "    metadata = []\n",
    "    for path, fileName in filtered_image_paths.items():\n",
    "        if fileName in meta_present:\n",
    "            images.append(path)\n",
    "            metadata.append(copy.deepcopy(metaDict[fileName]))\n",
    "\n",
    "    return [images, metadata]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carlo's Test Functions\n",
    "# Need to remove later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def test_iiif(config):\n",
    "    test_images = copy_root_dir/\"tests/IIIF_examples/iif_example.txt\"\n",
    "    test_out_dir = copy_root_dir/\"tests/smithsonian_butterflies_10/output_test_temp\"\n",
    "\n",
    "    if Path(test_out_dir).exists():\n",
    "        rmtree(test_out_dir)\n",
    "\n",
    "    config[\"images\"] = test_images.as_posix()\n",
    "    config[\"out_dir\"] = test_out_dir.as_posix()\n",
    "    config[\"plot_id\"] = \"test_diff\"\n",
    "\n",
    "    return config\n",
    "\n",
    "\n",
    "def test_butterfly_duplicate(config):\n",
    "    test_images = copy_root_dir/\"tests/smithsonian_butterflies_10/jpgs_duplicates/**/*.jpg\"\n",
    "    test_out_dir = copy_root_dir/\"tests/smithsonian_butterflies_10/output_test_temp\"\n",
    "    meta_dir = copy_root_dir/\"tests/smithsonian_butterflies_10/meta_data/good_meta.csv\"\n",
    "    if Path(test_out_dir).exists():\n",
    "        rmtree(test_out_dir)\n",
    "\n",
    "    config[\"images\"] = test_images.as_posix()\n",
    "    config[\"out_dir\"] = test_out_dir.as_posix()\n",
    "    config[\"meta_dir\"] = meta_dir.as_posix()\n",
    "    config[\"plot_id\"] = \"test_diff\"\n",
    "\n",
    "    return config\n",
    "\n",
    "\n",
    "def test_butterfly(config):\n",
    "    test_images = copy_root_dir/\"tests/smithsonian_butterflies_10/jpgs/*.jpg\"\n",
    "    test_out_dir = copy_root_dir/\"tests/smithsonian_butterflies_10/output_test_temp\"\n",
    "    meta_dir = copy_root_dir/\"tests/smithsonian_butterflies_10/meta_data/good_meta.csv\"\n",
    "    if Path(test_out_dir).exists():\n",
    "        rmtree(test_out_dir)\n",
    "\n",
    "    config[\"images\"] = test_images.as_posix()\n",
    "    config[\"out_dir\"] = test_out_dir.as_posix()\n",
    "    config[\"meta_dir\"] = meta_dir.as_posix()\n",
    "    config[\"plot_id\"] = \"test_diff\"\n",
    "    \n",
    "    config[\"test_mode\"] = True\n",
    "\n",
    "    return config\n",
    "\n",
    "\n",
    "def test_butterfly_missing_meta(config):\n",
    "    test_images = copy_root_dir/\"tests/smithsonian_butterflies_10/jpgs/*.jpg\"\n",
    "    test_out_dir = copy_root_dir/\"tests/smithsonian_butterflies_10/output_test_temp\"\n",
    "    meta_dir = copy_root_dir/\"tests/smithsonian_butterflies_10/meta_data/meta_missing_filename.csv\"\n",
    "    if Path(test_out_dir).exists():\n",
    "        rmtree(test_out_dir)\n",
    "\n",
    "    config[\"images\"] = test_images.as_posix()\n",
    "    config[\"out_dir\"] = test_out_dir.as_posix()\n",
    "    config[\"meta_dir\"] = meta_dir.as_posix()\n",
    "    config[\"plot_id\"] = \"test_diff\"\n",
    "\n",
    "    return config\n",
    "\n",
    "\n",
    "def test_no_meta_dir(config):\n",
    "    test_images = copy_root_dir/\"tests/smithsonian_butterflies_10/jpgs/*.jpg\"\n",
    "    test_out_dir = copy_root_dir/\"tests/smithsonian_butterflies_10/output_test_temp\"\n",
    "    if Path(test_out_dir).exists():\n",
    "        rmtree(test_out_dir)\n",
    "\n",
    "    config[\"images\"] = test_images.as_posix()\n",
    "    config[\"out_dir\"] = test_out_dir.as_posix()\n",
    "    config[\"plot_id\"] = \"test_diff\"\n",
    "\n",
    "    return config\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse the command-line arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@call_parse\n",
    "def project_imgs(images:Param(type=str,\n",
    "                        help=\"path or glob of images to process\"\n",
    "                        )=DEFAULTS[\"images\"],\n",
    "                embeds:Param(type=str,\n",
    "                        help=\"path or glob of embeddings to process (must match images folder/file structure)\"\n",
    "                        )=DEFAULTS[\"embeds\"],\n",
    "                metadata:Param(type=str,\n",
    "                        help=\"path to a csv or glob of JSON files with image metadata (see readme for format)\"\n",
    "                        )=DEFAULTS[\"meta_dir\"],\n",
    "                max_images:Param(type=int,\n",
    "                        help=\"maximum number of images to process\"\n",
    "                        )=DEFAULTS[\"max_images\"],\n",
    "                use_cache:Param(type=bool,\n",
    "                        help=\"given inputs identical to prior inputs, load outputs from cache\"\n",
    "                        )=DEFAULTS[\"use_cache\"],\n",
    "                encoding:Param(type=str,\n",
    "                        help=\"the encoding of input metadata\"\n",
    "                        )=DEFAULTS[\"encoding\"],\n",
    "                min_cluster_size:Param(type=int,\n",
    "                        help=\"the minimum number of images in a cluster\",\n",
    "                        required=False\n",
    "                        )=DEFAULTS[\"min_cluster_size\"],\n",
    "                max_clusters:Param(type=int,\n",
    "                        help=\"the maximum number of clusters to return\",\n",
    "                        required=False\n",
    "                        )=DEFAULTS[\"max_clusters\"],\n",
    "                out_dir:Param(type=str,\n",
    "                        help=\"the directory to which outputs will be saved\",\n",
    "                        required=False\n",
    "                        )=DEFAULTS[\"out_dir\"],\n",
    "                cell_size:Param(type=int,\n",
    "                        help=\"the size of atlas cells in px\",\n",
    "                        required=False\n",
    "                        )=DEFAULTS[\"cell_size\"],\n",
    "                n_neighbors:Param(type=int,\n",
    "                        nargs=\"+\",\n",
    "                        help=\"the n_neighbors arguments for UMAP\"\n",
    "                        )=DEFAULTS[\"n_neighbors\"],\n",
    "                min_dist:Param(type=float,\n",
    "                        nargs=\"+\",\n",
    "                        help=\"the min_dist arguments for UMAP\"\n",
    "                        )=DEFAULTS[\"min_dist\"],\n",
    "                n_components:Param(type=int,\n",
    "                        help=\"the n_components argument for UMAP\"\n",
    "                        )=DEFAULTS[\"n_components\"],\n",
    "                metric:Param(type=str,\n",
    "                        help=\"the metric argument for umap\"\n",
    "                        )=DEFAULTS[\"metric\"],\n",
    "                pointgrid_fill:Param(type=float,\n",
    "                        help=\"float 0:1 that determines sparsity of jittered distributions (lower means more sparse)\"\n",
    "                        )=DEFAULTS[\"pointgrid_fill\"],\n",
    "                copy_web_only:Param(type=bool,\n",
    "                        action=\"store_true\",\n",
    "                        help=\"update ./output/assets without reprocessing data\"\n",
    "                        )=False,\n",
    "                min_size:Param(type=float,\n",
    "                        help=\"min size of cropped images\"\n",
    "                        )=DEFAULTS[\"min_size\"],\n",
    "                gzip:Param(type=bool,\n",
    "                        action=\"store_true\", help=\"save outputs with gzip compression\"\n",
    "                        )=False,\n",
    "                shuffle:Param(type=bool,\n",
    "                        action=\"store_true\",\n",
    "                        help=\"shuffle the input images before data processing begins\"\n",
    "                        )=False,\n",
    "                plot_id:Param(type=str,\n",
    "                        help=\"unique id for a plot; useful for resuming processing on a started plot\"\n",
    "                        )=DEFAULTS[\"plot_id\"],\n",
    "                seed:Param(type=int, help=\"seed for random processes\"\n",
    "                           )=DEFAULTS[\"seed\"],\n",
    "                n_clusters:Param(type=int,\n",
    "                        help=\"number of clusters if using kmeans\"\n",
    "                        )=DEFAULTS[\"n_clusters\"],\n",
    "                geojson:Param(type=str,\n",
    "                        help=\"path to a GeoJSON file with shapes to be rendered on a map\"\n",
    "                        )=DEFAULTS[\"geojson\"]\n",
    "                ):\n",
    "                \"Convert a folder of images into a clip-plot visualization\"\n",
    "\n",
    "                # grab local variables as configuration dict\n",
    "                config = locals()\n",
    "\n",
    "                # some parameters exist in DEFAULTS but not in the function signature\n",
    "                default_only_keys = set(set(DEFAULTS.keys() - config.keys()))\n",
    "                default_only = {k:DEFAULTS[k] for k in default_only_keys}\n",
    "                config.update(default_only)\n",
    "\n",
    "                copy_root_dir = get_clip_plot_root()\n",
    "\n",
    "                if in_ipython() and config[\"images\"] == None:\n",
    "                        print(\"we're in ipython\")\n",
    "                        # at least for now, this means we're in testing mode.\n",
    "                        # TODO: pass explicit \"test_mode\" flag\n",
    "                        config = test_butterfly(config)\n",
    "\n",
    "                options = {\n",
    "                        'shuffle': False, \n",
    "                        'seed': config['seed'], \n",
    "                        'max_images': False, \n",
    "                        'atlas_size': 2048, \n",
    "                        'cell_size': 32, \n",
    "                        'lod_cell_height': 128, \n",
    "                        'validate': True, \n",
    "                }\n",
    "                imageEngine = ImageFactory(config['images'], config['out_dir'], config['meta_dir'], options)\n",
    "\n",
    "                process_images(imageEngine, **config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    project_imgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
