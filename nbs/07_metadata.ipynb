{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "from glob import glob\n",
    "from math import ceil\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "from typing import Optional, List, Union\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from clip_plot.utils import clean_filename, FILE_NAME\n",
    "from clip_plot.layouts import get_layouts, get_heightmap, get_hotspots\n",
    "from clip_plot.utils import is_number, get_version, write_json, read_json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle metadata (dates, categories, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_metadata_list(meta_dir: str) -> list[dict] | list[str]:\n",
    "    \"\"\"Return a list of objects with image metadata.\n",
    "\n",
    "    Will create 'tags' key if 'category' is in metadata\n",
    "    but not 'tags'.\n",
    "\n",
    "    Args:\n",
    "        metadata (str, default = None): Metadata location\n",
    "\n",
    "    Returns:\n",
    "        l (List[dict]): List of metadata\n",
    "\n",
    "    Notes:\n",
    "        No check for 'filename' is performed\n",
    "\n",
    "    Todo:\n",
    "        Think about separating .csv and json functionality.\n",
    "        Can we use pandas numpy to process csv?\n",
    "    \"\"\"\n",
    "    # handle csv metadata\n",
    "    metaList = []\n",
    "    if meta_dir.endswith(\".csv\"):\n",
    "        with open(meta_dir) as f:\n",
    "            reader = csv.reader(f)\n",
    "            headers = [i.lower() for i in next(reader)]\n",
    "            for i in reader:\n",
    "                metaList.append(\n",
    "                    {\n",
    "                        headers[j]: i[j] if len(i) > j and i[j] else \"\"\n",
    "                        for j, _ in enumerate(headers)\n",
    "                    }\n",
    "                )\n",
    "    \n",
    "    # handle json metadata\n",
    "    else:\n",
    "        for i in glob(meta_dir, recursive=True):\n",
    "            with open(i) as f:\n",
    "                metaList.append(json.load(f))\n",
    "\n",
    "    # if the user provided a category but not a tag, use the category as the tag\n",
    "    for metaDict in metaList:\n",
    "        if \"category\" in metaDict and (\"tags\" in metaDict) is False:\n",
    "            metaDict.update({\"tags\": metaDict[\"category\"]})\n",
    "    return metaList, headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def write_metadata(imageEngine):\n",
    "    \"\"\"\n",
    "    Write list `metadata` of objects to disk\n",
    "    Tightly coupled to ImageEngine class\n",
    "    \"\"\"\n",
    "    metadata = imageEngine.metadata\n",
    "    data_dir = imageEngine.data_dir\n",
    "    if not metadata:\n",
    "        return\n",
    "\n",
    "    meta_dir = data_dir / \"metadata\"\n",
    "    for subdir in [\"filters\", \"options\", \"file\"]:\n",
    "        (meta_dir / subdir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Create the lists of images with each tag\n",
    "    d = defaultdict(list)\n",
    "    for img in imageEngine:\n",
    "        row = img.metadata\n",
    "        filename = img.unique_name\n",
    "        row[\"tags\"] = [j.strip() for j in row.get(\"tags\", \"\").split(\"|\")]\n",
    "        for j in row[\"tags\"]:\n",
    "            d[\"__\".join(j.split())].append(filename)\n",
    "        write_json((meta_dir/\"file\"/f\"{filename}.json\"), row)\n",
    "\n",
    "    write_json(\n",
    "        (meta_dir/\"filters\"/\"filters.json\"),\n",
    "        [{\"filter_name\": \"select\",\n",
    "          \"filter_values\": list(d.keys()),\n",
    "        }],\n",
    "    )\n",
    "\n",
    "    # create the options for the category dropdown\n",
    "    for i in d:\n",
    "        write_json((meta_dir/\"options\"/ f\"{i}.json\"), d[i])\n",
    "\n",
    "    # create the map from date to images with that date (if dates present)\n",
    "    date_d = defaultdict(list)\n",
    "    for i in metadata:\n",
    "        date = i.get(\"year\", \"\")\n",
    "        if date:\n",
    "            date_d[date].append(clean_filename(i[FILE_NAME]))\n",
    "\n",
    "    # find the min and max dates to show on the date slider\n",
    "    dates = np.array([int(i.strip()) for i in date_d if is_number(i)])\n",
    "    domain = {\"min\": float(\"inf\"), \"max\": -float(\"inf\")}\n",
    "    mean = np.mean(dates)\n",
    "    std = np.std(dates)\n",
    "    for i in dates:\n",
    "        # update the date domain with all non-outlier dates\n",
    "        if abs(mean - i) < (std * 4):\n",
    "            domain[\"min\"] = int(min(i, domain[\"min\"]))\n",
    "            domain[\"max\"] = int(max(i, domain[\"max\"]))\n",
    "\n",
    "    # write the dates json\n",
    "    if len(date_d) > 1:\n",
    "        write_json(\n",
    "            (meta_dir/\"dates.json\"),\n",
    "            {\"domain\": domain, \"dates\": date_d,},\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_manifest(imageEngine, atlas_data,\n",
    "                 plot_id: str | None,\n",
    "                 output_dir: Path,\n",
    "                 has_metadata: bool = False,\n",
    "                 ):\n",
    "    \"\"\"\n",
    "    Create and return the base object for the manifest output file\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    data_dir = output_dir/\"data\"\n",
    "    # store each cell's size and atlas position\n",
    "    atlas_ids = {i[\"idx\"] for i in atlas_data}\n",
    "    sizes = [[] for _ in atlas_ids]\n",
    "    pos = [[] for _ in atlas_ids]\n",
    "    for i in atlas_data:\n",
    "        sizes[i[\"idx\"]].append([i[\"w\"], i[\"h\"]])\n",
    "        pos[i[\"idx\"]].append([i[\"x\"], i[\"y\"]])\n",
    "\n",
    "    # obtain the paths to each layout's JSON positions\n",
    "    layouts = get_layouts(imageEngine, **kwargs)\n",
    "    # create a heightmap for the umap layout\n",
    "    if \"umap\" in layouts and layouts[\"umap\"]:\n",
    "        get_heightmap(layouts[\"umap\"][\"variants\"][0][\"layout\"], \"umap\", **kwargs)\n",
    "\n",
    "    # specify point size scalars\n",
    "    point_sizes = {}\n",
    "    point_sizes[\"min\"] = 0\n",
    "    point_sizes[\"grid\"] = 1 / ceil(imageEngine.count ** (1 / 2))\n",
    "    point_sizes[\"max\"] = point_sizes[\"grid\"] * 1.2\n",
    "    point_sizes[\"scatter\"] = point_sizes[\"grid\"] * 0.2\n",
    "    point_sizes[\"initial\"] = point_sizes[\"scatter\"]\n",
    "    point_sizes[\"categorical\"] = point_sizes[\"grid\"] * 0.6\n",
    "    point_sizes[\"geographic\"] = point_sizes[\"grid\"] * 0.025\n",
    "\n",
    "    # fetch the date distribution data for point sizing\n",
    "    if \"date\" in layouts and layouts[\"date\"]:\n",
    "        date_layout = read_json(layouts[\"date\"][\"labels\"])\n",
    "        point_sizes[\"date\"] = 1 / (\n",
    "            (date_layout[\"cols\"] + 1) * len(date_layout[\"labels\"])\n",
    "        )\n",
    "\n",
    "    # create manifest json\n",
    "    manifest = {\n",
    "        \"version\": get_version(),\n",
    "        \"plot_id\": plot_id,\n",
    "        \"output_directory\": output_dir.as_posix(),\n",
    "        \"layouts\": layouts,\n",
    "        \"initial_layout\": \"umap\",\n",
    "        \"point_sizes\": point_sizes,\n",
    "        \"imagelist\": (data_dir / \"imagelist.json\").as_posix(),\n",
    "        \"atlas_dir\": (data_dir/\"atlases\").as_posix(),\n",
    "        \"metadata\": has_metadata,\n",
    "        \"default_hotspots\": get_hotspots(imageEngine, layouts=layouts,\n",
    "                                         n_preproc_dims=kwargs[\"cluster_preproc_dims\"],\n",
    "                                         **kwargs),\n",
    "        \"custom_hotspots\": data_dir/\"hotspots/user_hotspots.json\",\n",
    "        \"gzipped\": False,\n",
    "        \"config\": {\n",
    "            \"sizes\": {\n",
    "                \"atlas\": imageEngine.atlas_size,\n",
    "                \"cell\": imageEngine.cell_size,\n",
    "                \"lod\": imageEngine.lod_cell_height,\n",
    "            },\n",
    "        },\n",
    "        \"creation_date\": datetime.today().strftime(\"%d-%B-%Y-%H:%M:%S\"),\n",
    "    }\n",
    "\n",
    "    # # store parameters that will impact embedding\n",
    "    # embed_params = [\"embed_model\", \"n_neighbors\", \"min_dist\", \"metric\", \"max_clusters\", \"min_cluster_size\"]\n",
    "    # for e in embed_params:\n",
    "    #     manifest.update({e: kwargs[e]})\n",
    "\n",
    "    write_json(data_dir/\"manifests/manifest.json\", manifest)\n",
    "    write_json(data_dir/\"/manifest.json\", manifest)\n",
    "\n",
    "    imagelist = {\n",
    "        \"cell_sizes\": sizes,\n",
    "        \"images\": [img.unique_name for img in imageEngine],\n",
    "        \"atlas\": {\n",
    "            \"count\": len(atlas_ids),\n",
    "            \"positions\": pos,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    write_json(data_dir / \"imagelist.json\", imagelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clipplot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
