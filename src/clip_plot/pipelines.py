# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/13_pipelines.ipynb.

# %% auto 0
__all__ = ['project_images_pipeline', 'embed_images_pipeline']

# %% ../../nbs/13_pipelines.ipynb 3
# print separately that we're loading dependencies, as this can take a while
# and we want to give immediate feedback the program is starting
from .utils import timestamp
print(timestamp(), "Beginning to load dependencies")

# %% ../../nbs/13_pipelines.ipynb 4
from fastcore.all import in_ipython
from tqdm.auto import tqdm

from .configuration import Cfg, ClusterSpec, ImageLoaderOptions, UmapSpec, ViewerOptions
from .embeddings import get_embeddings, write_embeddings
from .from_tables import cat_tables, table_to_meta
from .images import ImageFactory, create_atlases_and_thumbs
from .metadata import get_manifest, write_metadata
from .web_config import copy_web_assets, get_clip_plot_root


# %% ../../nbs/13_pipelines.ipynb 5
from pathlib import Path
from shutil import rmtree

import numpy as np
import polars as pl


# %% ../../nbs/13_pipelines.ipynb 7
def project_images_pipeline(output_dir: Path,
                            plot_id: str,
                            model: str,
                            viewer_opts: ViewerOptions,
                            umap_spec: UmapSpec,
                            cluster_spec: ClusterSpec,
                            image_opts: ImageLoaderOptions,
                            images: list[Path] | None = None,
                            tables: list[Path] | None = None,
                            metadata: list[Path] | None = None,
                            image_path_col: str = "image_path",
                            vectors_col: str = "hidden_vectors",
        ):
        """Convert a folder of images into a clip-plot visualization"""

        if tables and images:
                raise ValueError("Provide either tables or images parameter, not both.")
        if not tables and not images:
                raise ValueError("No images found from either tables or images input.")
        if tables and not images:
                print(timestamp(), "Loading tables")
                table: pd.DataFrame | None = cat_tables(tables)
                images: list[Path] = [Path(p) for p in table[image_path_col].to_numpy()]
                print(timestamp(), "Loading embeddings from disk")
                hidden_vectors: np.ndarray | None = table[vectors_col].to_numpy()
                imageEngine.meta_headers, imageEngine.metadata = table_to_meta(table)
        elif not tables and images:
                hidden_vectors = get_embeddings(images, model_name=model)

        data_dir = output_dir / "data"
        imageEngine = ImageFactory(images, data_dir, metadata,
                                        **image_opts.model_dump(),)

        print(f"Config to project images: {str(image_opts.model_dump())}")

        np.random.seed(image_opts.seed)
        print(timestamp(), "Starting image processing pipeline.")

        copy_web_assets(output_dir=output_dir,
                        tagline=viewer_opts.tagline, logo=viewer_opts.logo)
        write_metadata(imageEngine)
        _, atlas_data = create_atlases_and_thumbs(imageEngine, plot_id)

        get_manifest(imageEngine, atlas_data, hidden_vectors,
                        plot_id=plot_id, output_dir=output_dir,
                        umap_spec=umap_spec, cluster_spec=cluster_spec
        )
        # write_images(imageEngine)
        print(timestamp(), "Done!")

# %% ../../nbs/13_pipelines.ipynb 9
def embed_images_pipeline(images: list[Path],
                     model: str,
                     metadata: list[Path] | None,
                     output_dir: Path,
                     table_format: str,
                     table_id: str,
                ):
                """Embed a folder of images, save embeddings as .npy file to disk"""
                output_dir = Path(output_dir)
                data_dir = output_dir / "data"

                imageEngine = ImageFactory(image_paths=images, data_dir=data_dir, metadata_paths=metadata)

                embeddings = get_embeddings(image_paths=images, model_name=model)
                df = pl.DataFrame({"image_path": images,
                                   "image_filename": imageEngine.filenames,
                                   "hidden_vectors": embeddings,
                })

                if len(imageEngine.metadata) > 0:
                        df_meta = pl.DataFrame(imageEngine.metadata)
                        df_meta = df_meta.rename({"filename": "image_filename"})
                        # drop "image_path" column if df_meta has it
                        if "image_path" in df_meta.columns:
                                df_meta = df_meta.drop("image_path")

                        df = df.join(df_meta.unique(subset=["image_filename"]), on="image_filename",
                                              how="left")

                df = df.with_columns(pl.col("image_path").cast(pl.Utf8))

                ## standardize sort order of table
                # put standard columns in a sensible order if they exist in df
                standard_cols: set[str] = {"image_path", "image_filename", "hidden_vectors",
                                                   "category", "tags", "x", "y"}
                cols_in_order = list(standard_cols & set(df.columns))
                # append non-standard columns, sorted alphabetically
                non_standard_cols: list[str] = sorted(set(df.columns) - standard_cols)
                cols_sorted = cols_in_order + non_standard_cols
                df = df.with_columns(cols_sorted)


                if table_format == "csv":
                        df.write_csv(data_dir / f"EmbedImages__{table_id}.csv")
                else:
                        df.write_parquet(data_dir / f"EmbedImages__{table_id}.parquet")
