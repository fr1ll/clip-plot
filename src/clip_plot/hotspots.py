# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/12_hotspots.ipynb.

# %% auto 0
__all__ = ['get_cluster_model', 'get_hotspots']

# %% ../../nbs/12_hotspots.ipynb 2
import multiprocessing
from collections import defaultdict
from pathlib import Path

import numpy as np
from hdbscan import HDBSCAN

from .configuration import ClusterSpec
from .images import ImageFactory
from .utils import get_json_path, timestamp, write_json


# %% ../../nbs/12_hotspots.ipynb 3
def get_cluster_model(min_cluster_size: int = 15):
    """Return model with .fit() method that can be used to cluster input vectors
    """
    return HDBSCAN(
        core_dist_n_jobs=multiprocessing.cpu_count(),
        min_cluster_size=min_cluster_size,
        cluster_selection_epsilon=0.01,
        min_samples=1,
        approx_min_span_tree=False,
    )

# %% ../../nbs/12_hotspots.ipynb 4
def get_hotspots(imageEngine: ImageFactory,
                 vecs: np.ndarray,
                 data_dir: Path, plot_id: str,
                 cluster_spec: ClusterSpec,
                 layout_name: str = "umap_base_layout",
                ):
    """Return the stable clusters from the condensed tree of connected components from the density graph
    """
    print(timestamp(), "Clustering data with HDBSCAN")
    model = get_cluster_model(cluster_spec.min_cluster_size)
    z = model.fit(vecs)

    # create a map from cluster label to image indices in cluster
    d = defaultdict(lambda: defaultdict(list))
    for idx, i in enumerate(z.labels_):
        if i != -1:
            d[i]["images"].append(idx)
            d[i]["img"] = imageEngine[idx].unique_name
            d[i]["layout"] = layout_name

    # remove massive clusters
    deletable = []
    for i in d:
        # find percent of images in cluster
        image_percent = len(d[i]["images"]) / len(vecs)
        # determine if image or area percent is too large
        if image_percent > 0.5:
            deletable.append(i)
    for i in deletable:
        del d[i]

    # sort the clusers by size and then label the clusters
    clusters = d.values()
    clusters = sorted(clusters, key=lambda i: len(i["images"]), reverse=True)
    for idx, i in enumerate(clusters):
        i["label"] = f"Cluster {idx + 1}"

    # slice off the first `max_clusters`
    clusters = clusters[: cluster_spec.max_clusters]

    # save the hotspots to disk and return the path to the saved json
    print(timestamp(), "Found", len(clusters), "hotspots")
    json_path = get_json_path(data_dir, "hotspots", plot_id, "hotspot",)
    write_json(json_path, data_dir=data_dir, obj=clusters)
    return json_path
