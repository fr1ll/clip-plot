# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/04_embeddings.ipynb.

# %% auto 0
__all__ = ['accelerator', 'timm_embed_model', 'timm_transform_embed', 'get_timm_embeds']

# %% ../nbs/04_embeddings.ipynb 3
from .utils import timestamp, clean_filename
from .images import image_to_array, Image

from pathlib import Path
from more_itertools import chunked

import torch
import timm
from torchvision.transforms.functional import pil_to_tensor
from accelerate import Accelerator

accelerator = Accelerator()


### Silence tensorflow
# import os
# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
# import tensorflow as tf

# from tensorflow.keras.applications import InceptionV3
# from tensorflow.keras.models import Model
# from tensorflow.keras.applications.inception_v3 import preprocess_input

from tqdm.auto import tqdm
import numpy as np

# %% ../nbs/04_embeddings.ipynb 5
def timm_embed_model(model_name: str):
    '''
    Load model and image transform to create embeddings
    Reference: https://huggingface.co/docs/timm/main/en/feature_extraction#pooled

    input:          model name as found in timm documentation
    return tuple:   pre-trained embedding model,
                    transform function to prep images for inference
    '''

    m = timm.create_model(model_name, pretrained=True, num_classes=0)
    m.eval()

    # Reference on transform: https://huggingface.co/docs/timm/main/en/feature_extraction#pooled
    t = timm.data.create_transform(
        **timm.data.resolve_data_config(m.pretrained_cfg)
    )
    print(f"CUDA is available? {torch.cuda.is_available()}")
    return m, t

def timm_transform_embed(img, model, transform, device, dtype) -> np.ndarray:
    '''
    apply transform to image and run inference on it to generate an embedding

    input:      img: Pillow image or similar
                model: Torch model
                transform: Torch image transformation pipeline to match how model was trained
    returns: embedding vector as 1D numpy array
    '''
    img = transform(img).to(device, dtype).unsqueeze(0)
    emb = model(img)
    return emb.detach().cpu().numpy().squeeze()

def get_timm_embeds(imageEngine, model_name: str, **kwargs):
    '''
    Create embedding vectors for input images using a pre-trained model from timm
    '''
    vector_dir = Path(kwargs["out_dir"]) / "image-vectors" / "inception"
    vector_dir.mkdir(exist_ok=True, parents=True)

    torch.manual_seed(kwargs["seed"])

    print(timestamp(), f"Creating embeddings using {model_name}")
    embeds = []

    model, transform = timm_embed_model(model_name)
    device = accelerator.device
    torch_dtype = torch.float16
    model = accelerator.prepare(model)
    model = model.to(device, torch_dtype)

    for img in tqdm(imageEngine, total=imageEngine.count):
        embed_path = vector_dir / (clean_filename(img.path) + ".npy")
        if embed_path.exists() and kwargs["use_cache"]:
            vec = np.load(embed_path)
        else:
            emb = timm_transform_embed(img.original, model, transform, device, torch_dtype)
            np.save(embed_path, emb)
        embeds.append(emb)
    return np.array(embeds)

# %% ../nbs/04_embeddings.ipynb 6
# def get_inception_vectors(imageEngine, **kwargs):
#     """Create and return Inception vector representation of Image() instances"""

#     vector_dir = Path(kwargs["out_dir"]) / "image-vectors" / "inception"
#     vector_dir.mkdir(exist_ok=True, parents=True)
#     base = InceptionV3(
#         include_top=True,
#         weights="imagenet",
#     )
#     model = Model(inputs=base.input, outputs=base.get_layer("avg_pool").output)
#     tf.random.set_seed(kwargs["seed"])

#     print(timestamp(), "Creating Inception vectors")
#     vecs = []   

#     for img in tqdm(imageEngine, total=imageEngine.count):
#         vector_path = vector_dir / (clean_filename(img.path) + ".npy")
#         if vector_path.exists() and kwargs["use_cache"]:
#             vec = np.load(vector_path)
#         else:
#             img_processed = preprocess_input(image_to_array(img.original.resize((299, 299))))
#             vec = model.predict(np.expand_dims(img_processed, 0), verbose = 0).squeeze()
#             np.save(vector_path, vec)
#         vecs.append(vec)
#     return np.array(vecs)
