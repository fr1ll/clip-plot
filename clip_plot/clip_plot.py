# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/00_clip_plot.ipynb.

# %% ../nbs/00_clip_plot.ipynb 3
from __future__ import division
import warnings

warnings.filterwarnings("ignore")

# %% auto 0
__all__ = ['PILLoadTruncated', 'project_images', 'embed_images', 'embed_images_cli']

# %% ../nbs/00_clip_plot.ipynb 4
# print separately that we're loading dependencies, as this can take a while
# and we want to give immediate feedback the program is starting
from .utils import timestamp
print(timestamp(), "Beginning to load dependencies")

# %% ../nbs/00_clip_plot.ipynb 5
from fastcore.all import call_parse, in_ipython, Param
from tqdm.auto import tqdm

from .from_tables import cat_tables, table_to_meta
from .web_config import copy_web_assets, get_clip_plot_root
from .embeddings import get_embeddings, write_embeddings
from .metadata import get_manifest, write_metadata
from .images import create_atlases_and_thumbs, ImageFactory
from .configuration import UmapSpec, ClusterSpec, ViewerOptions, ImageLoaderOptions

# %% ../nbs/00_clip_plot.ipynb 6
from shutil import rmtree
from pathlib import Path
import uuid
import pandas as pd
import numpy as np

# %% ../nbs/00_clip_plot.ipynb 9
_DEFAULTS = {
    "images": None,
    "tables": None,
    "metadatas": None,
    "output_dir": "output",
    "max_images": None,
    "min_cluster_size": 20,
    "max_clusters": 10,
    "atlas_size": 2048,
    "cell_size": 32,
    "lod_cell_height": 128, # Why is not in parser?
    "model": "timm/convnext_tiny.dinov3_lvd1689m",
    "n_neighbors": [15],
    "min_dist": [0.01],
    "metric": "correlation",
    "min_size": 100,
    "plot_id": str(uuid.uuid1()),
    "seed": 42,
    "n_clusters": 12,
}

# handle truncated images in PIL (managed by Pillow)
PILLoadTruncated  = True

## Keras Image class objects return image.size as w,h
## Numpy array representations of images return image.shape as h,w,c

# %% ../nbs/00_clip_plot.ipynb 11
def _project_images(imageEngine,
                    output_dir: Path,
                    plot_id: str,
                    model: str,
                    umap_spec: UmapSpec,
                    cluster_spec: ClusterSpec,
                    viewer_opts: ViewerOptions,
                    hidden_vectors: np.ndarray | None,
):
    """
    Main method for embedding user images, projecting to 2D, and creating visualization
    It would be nice to list out the image processing steps before getting started
    """


    print(timestamp(), "Starting image processing pipeline.")

    copy_web_assets(output_dir=output_dir,
                    tagline=viewer_opts.tagline, logo=viewer_opts.logo)

    write_metadata(imageEngine)

    _, atlas_data = create_atlases_and_thumbs(imageEngine, plot_id)

    if hidden_vectors is None:
        hidden_vectors = get_embeddings(imageEngine, model_name=model)

    get_manifest(imageEngine, atlas_data, hidden_vectors,
                 plot_id=plot_id, output_dir=output_dir,
                 umap_spec=umap_spec, cluster_spec=cluster_spec
                 )
    # write_images(imageEngine)
    print(timestamp(), "Done!")

# %% ../nbs/00_clip_plot.ipynb 12
def project_images_pipeline(output_dir: Path,
                            images: list[Path] | None = None,
                            tables: list[Path] | None = None,
                            metadata: list[Path] | None = None,
                            image_path_col: str | None = None,
                            embed_path_col: str | None = None,
                            image_opts: ImageLoaderOptions,
                            viewer_opts: ViewerOptions,
                            umap_spec: UmapSpec,
                            cluster_spec: ClusterSpec
                ):
                """Convert a folder of images into a clip-plot visualization"""

                if tables and images:
                        raise ValueError("Provide either tables or images parameter, not both.")
                if tables:
                        print(timestamp(), "Loading tables")
                        table = cat_tables(tables)
                        images = list(table[image_path_col].values)
                        print(timestamp(), "Loading embeddings from disk")
                        hidden_vectors = np.array([np.load(e) for e in tqdm(table[embed_path_col])])
                else:
                        hidden_vectors = None
                        table = None

                data_dir = output_dir / "data"
                imageEngine = ImageFactory(images, data_dir, metadata,
                                           **image_opts.model_dump(),)

                # grab metadata from table if provided
                if table is not None:
                        imageEngine.meta_headers, imageEngine.metadata = table_to_meta(table)

                print(f"Config to project images: {str(im_opts.model_dump())}")

                np.random.seed(image_opts.seed) 

                _project_images(imageEngine, output_dir = output_dir,
                                plot_id,
                                model=model,
                                cluster_spec=cluster_spec,
                                umap_spec=umap_spec,
                                hidden_vectors=hidden_vectors,
                                viewer_opts=viewer_opts
                                )

# %% ../nbs/00_clip_plot.ipynb 13
# awful workaround because I think call_parse only works with sys.argv (cli)
project_images = project_images_cli.__wrapped__

# %% ../nbs/00_clip_plot.ipynb 15
@call_parse
def embed_images_cli(images:Param(type=str,
                        help="path or glob of images to process"
                        )=_DEFAULTS["images"],
                model:Param(type=str,
                        help="pre-trained model from timm library to use to create embedding",
                        required=False
                        )=_DEFAULTS["model"],
                output_dir:Param(type=str,
                        help="the directory to which outputs will be saved",
                        required=False
                        )=_DEFAULTS["output_dir"],
                metadata:Param(type=str,
                        help="path to a csv or glob of JSON files with image metadata (see readme for format)"
                        )=_DEFAULTS["metadatas"],
                table_id:Param(type=str,
                        help="identifier for table that links embeddings to images and (optionally) metadata",
                        required=False
                        )=str(uuid.uuid1()),
                table_format:Param(type=str,
                        choices=["parquet", "csv"],
                        help="format for table linking embeddings, images, and metadata",
                        required=False
                        )="parquet"
                ):
                "Embed a folder of images and save embeddings as .npy file to disk"
                output_dir = Path(output_dir)

                # using Path.cwd() to handle ../ names -- not sure if this is superstitious
                data_dir = Path.cwd() / output_dir.resolve() / "data"

                imageEngine = ImageFactory(img_path=images, data_dir=data_dir, metadatas=metadata)

                embeddings = get_embeddings(imageEngine, model_name=model)

                def _model_shortname(n: str) -> str:
                        return "__".join(n.split("/")[-2:])

                embs_dir = data_dir/f"embeddings_{_model_shortname(model)}"
                embs_dir.mkdir(parents=True, exist_ok=True)
                emb_paths = write_embeddings(embeddings, imageEngine.filenames, embs_dir)

                df = pd.DataFrame({"image_path": imageEngine.image_paths,
                                   "image_filename": imageEngine.filenames,
                                   "embed_path": [str(e) for e in emb_paths]})

                if len(imageEngine.metadata) > 0:
                        df_meta = pd.DataFrame(imageEngine.metadata)
                        df_meta = df_meta.rename(columns={"filename": "image_filename"})
                        # drop "image_path" column if df_meta has it
                        if "image_path" in df_meta.columns:
                                df_meta = df_meta.drop(columns=["image_path"])

                        df = df.merge(df_meta.drop_duplicates(["image_filename"]), on="image_filename")

                ## standardize sort order of table
                # put standard columns first if they exist in df
                standard_cols = pd.Index(["image_path", "image_filename", "embed_path", "category", "tags", "x", "y"])
                cols_sorted = standard_cols.intersection(df.columns)
                # append non-standard columns, sorted alphabetically
                cols_sorted = cols_sorted.append(df.columns.difference(standard_cols).sort_values())
                df = df[cols_sorted]

                if table_format == "csv":
                        df.to_csv(data_dir / f"EmbedImages__{table_id}.csv", index=False)
                else:
                        df.to_parquet(data_dir / f"EmbedImages__{table_id}.parquet", index=False)

# %% ../nbs/00_clip_plot.ipynb 16
# awful workaround because I think call_parse only works with sys.argv (cli)
embed_images = embed_images_cli.__wrapped__
